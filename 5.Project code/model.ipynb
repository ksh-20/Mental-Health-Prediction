{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a517ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.utils import resample\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b67612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('survey.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd2946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gender(gender):\n",
    "    gender = str(gender).strip().lower()\n",
    "    if gender in ['male', 'm', 'male-ish', 'maile', 'mal', 'cis male', 'man', 'msle', 'mail', 'make', 'malr', 'cis man']:\n",
    "        return 'Male'\n",
    "    elif gender in ['female', 'f', 'cis female', 'woman', 'femake', 'female (cis)', 'femail', 'cis-female/femme', 'female ', 'femail']:\n",
    "        return 'Female'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03df481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df_processed = df.copy()\n",
    "    df_processed = df_processed[pd.to_numeric(df_processed['Age'], errors='coerce').notnull()]\n",
    "    df_processed['Age'] = df_processed['Age'].astype(float)\n",
    "    median_age = df_processed[(df_processed['Age'] >= 15) & (df_processed['Age'] <= 70)]['Age'].median()\n",
    "    df_processed.loc[df_processed['Age'] < 15, 'Age'] = median_age\n",
    "    df_processed.loc[df_processed['Age'] > 70, 'Age'] = median_age\n",
    "    df_processed['Gender'] = df_processed['Gender'].apply(clean_gender)\n",
    "    country_counts = df_processed['Country'].value_counts()\n",
    "    rare_countries = country_counts[country_counts < 20].index\n",
    "    df_processed['Country'] = df_processed['Country'].apply(lambda x: 'Other' if x in rare_countries else x)\n",
    "\n",
    "    valid_family_history = ['Yes', 'No']\n",
    "    valid_work_interfere = ['Never', 'Rarely', 'Sometimes', 'Often']\n",
    "    valid_treatment = ['Yes', 'No']\n",
    "    df_processed = df_processed[df_processed['family_history'].isin(valid_family_history)]\n",
    "    df_processed = df_processed[df_processed['work_interfere'].isin(valid_work_interfere)]\n",
    "    df_processed = df_processed[df_processed['treatment'].isin(valid_treatment)]\n",
    "\n",
    "    features = ['Age', 'Gender', 'Country', 'self_employed', 'family_history',\n",
    "                'work_interfere', 'no_employees', 'remote_work', 'tech_company',\n",
    "                'benefits', 'care_options', 'wellness_program', 'seek_help',\n",
    "                'anonymity', 'leave', 'mental_health_consequence',\n",
    "                'phys_health_consequence', 'coworkers', 'supervisor',\n",
    "                'mental_health_interview', 'phys_health_interview',\n",
    "                'mental_vs_physical', 'obs_consequence']\n",
    "\n",
    "    categorical_columns = [col for col in features if df_processed[col].dtype == 'object' or col == 'Gender']\n",
    "    for col in categorical_columns:\n",
    "        df_processed[col] = df_processed[col].fillna(df_processed[col].mode()[0])\n",
    "\n",
    "    label_encoders = {}\n",
    "    for column in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[column] = le.fit_transform(df_processed[column].astype(str))\n",
    "        label_encoders[column] = le\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    df_processed[features] = imputer.fit_transform(df_processed[features])\n",
    "    scaler = StandardScaler()\n",
    "    df_processed['Age'] = scaler.fit_transform(df_processed[['Age']])\n",
    "    df_processed['treatment'] = df_processed['treatment'].astype(str)\n",
    "\n",
    "    df_majority = df_processed[df_processed['treatment'] == df_processed['treatment'].mode()[0]]\n",
    "    df_minority = df_processed[df_processed['treatment'] != df_processed['treatment'].mode()[0]]\n",
    "    df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "    df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "    X = df_balanced[features]\n",
    "    le_target = LabelEncoder()\n",
    "    y = le_target.fit_transform(df_balanced['treatment'])\n",
    "    return X, y, label_encoders, scaler, le_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d1b6084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X, y, label_encoders, scaler, le_target = preprocess_data(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87fb845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "all_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17a8d556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training and Evaluation of All Models ===\n",
      "\n",
      "--- Logistic Regression ---\n",
      "Accuracy: 0.7559\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.73       118\n",
      "           1       0.75      0.81      0.78       136\n",
      "\n",
      "    accuracy                           0.76       254\n",
      "   macro avg       0.76      0.75      0.75       254\n",
      "weighted avg       0.76      0.76      0.75       254\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 82  36]\n",
      " [ 26 110]]\n",
      "\n",
      "--- KNN ---\n",
      "Accuracy: 0.7165\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73       118\n",
      "           1       0.79      0.64      0.71       136\n",
      "\n",
      "    accuracy                           0.72       254\n",
      "   macro avg       0.73      0.72      0.72       254\n",
      "weighted avg       0.73      0.72      0.72       254\n",
      "\n",
      "Confusion Matrix:\n",
      " [[95 23]\n",
      " [49 87]]\n",
      "\n",
      "--- Decision Tree ---\n",
      "Accuracy: 0.8504\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       118\n",
      "           1       0.92      0.79      0.85       136\n",
      "\n",
      "    accuracy                           0.85       254\n",
      "   macro avg       0.86      0.86      0.85       254\n",
      "weighted avg       0.86      0.85      0.85       254\n",
      "\n",
      "Confusion Matrix:\n",
      " [[109   9]\n",
      " [ 29 107]]\n",
      "\n",
      "--- Random Forest ---\n",
      "Accuracy: 0.9213\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       118\n",
      "           1       0.93      0.92      0.93       136\n",
      "\n",
      "    accuracy                           0.92       254\n",
      "   macro avg       0.92      0.92      0.92       254\n",
      "weighted avg       0.92      0.92      0.92       254\n",
      "\n",
      "Confusion Matrix:\n",
      " [[109   9]\n",
      " [ 11 125]]\n",
      "\n",
      "--- Naive Bayes ---\n",
      "Accuracy: 0.7205\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.69       118\n",
      "           1       0.73      0.76      0.74       136\n",
      "\n",
      "    accuracy                           0.72       254\n",
      "   macro avg       0.72      0.72      0.72       254\n",
      "weighted avg       0.72      0.72      0.72       254\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 80  38]\n",
      " [ 33 103]]\n",
      "\n",
      "--- SVM ---\n",
      "Accuracy: 0.7795\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75       118\n",
      "           1       0.78      0.82      0.80       136\n",
      "\n",
      "    accuracy                           0.78       254\n",
      "   macro avg       0.78      0.78      0.78       254\n",
      "weighted avg       0.78      0.78      0.78       254\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 86  32]\n",
      " [ 24 112]]\n",
      "\n",
      "--- XGBoost ---\n",
      "Accuracy: 0.8701\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       118\n",
      "           1       0.93      0.82      0.87       136\n",
      "\n",
      "    accuracy                           0.87       254\n",
      "   macro avg       0.87      0.87      0.87       254\n",
      "weighted avg       0.88      0.87      0.87       254\n",
      "\n",
      "Confusion Matrix:\n",
      " [[110   8]\n",
      " [ 25 111]]\n",
      "\n",
      "--- AdaBoost ---\n",
      "Accuracy: 0.7480\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       118\n",
      "           1       0.74      0.82      0.78       136\n",
      "\n",
      "    accuracy                           0.75       254\n",
      "   macro avg       0.75      0.74      0.74       254\n",
      "weighted avg       0.75      0.75      0.75       254\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 79  39]\n",
      " [ 25 111]]\n",
      "\n",
      "--- Gradient Boosting ---\n",
      "Accuracy: 0.8386\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83       118\n",
      "           1       0.85      0.85      0.85       136\n",
      "\n",
      "    accuracy                           0.84       254\n",
      "   macro avg       0.84      0.84      0.84       254\n",
      "weighted avg       0.84      0.84      0.84       254\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 97  21]\n",
      " [ 20 116]]\n",
      "\n",
      "Best Model: Random Forest with Accuracy: 0.9213\n",
      "\n",
      "=== Final Model Evaluation ===\n",
      "Accuracy: 0.9212598425196851\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       118\n",
      "           1       0.93      0.92      0.93       136\n",
      "\n",
      "    accuracy                           0.92       254\n",
      "   macro avg       0.92      0.92      0.92       254\n",
      "weighted avg       0.92      0.92      0.92       254\n",
      "\n",
      "Confusion Matrix:\n",
      " [[109   9]\n",
      " [ 11 125]]\n",
      "\n",
      "Feature Importances:\n",
      "                       Feature  Importance\n",
      "5              work_interfere    0.194589\n",
      "0                         Age    0.093768\n",
      "4              family_history    0.073447\n",
      "10               care_options    0.062814\n",
      "6                no_employees    0.055009\n",
      "2                     Country    0.053817\n",
      "14                      leave    0.040972\n",
      "20      phys_health_interview    0.037498\n",
      "9                    benefits    0.036751\n",
      "17                  coworkers    0.036009\n",
      "18                 supervisor    0.035799\n",
      "15  mental_health_consequence    0.033810\n",
      "1                      Gender    0.032775\n",
      "12                  seek_help    0.030743\n",
      "21         mental_vs_physical    0.030350\n",
      "13                  anonymity    0.027900\n",
      "11           wellness_program    0.023639\n",
      "16    phys_health_consequence    0.021643\n",
      "7                 remote_work    0.019259\n",
      "22            obs_consequence    0.016363\n",
      "8                tech_company    0.016339\n",
      "19    mental_health_interview    0.016103\n",
      "3               self_employed    0.010603\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_score = 0\n",
    "best_model_name = ''\n",
    "\n",
    "print(\"\\n=== Training and Evaluation of All Models ===\")\n",
    "for name, model in all_models.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    if acc > best_score:\n",
    "        best_score = acc\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} with Accuracy: {best_score:.4f}\")\n",
    "print(\"\\n=== Final Model Evaluation ===\")\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    print(\"\\nFeature Importances:\\n\", importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65648f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model and preprocessing objects with pickle...\n",
      "Saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save using pickle\n",
    "print(\"\\nSaving model and preprocessing objects with pickle...\")\n",
    "with open('mental_health_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open('label_encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "print(\"Saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f262d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict_mental_health(input_data):\n",
    "    with open('mental_health_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    with open('scaler.pkl', 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    with open('label_encoders.pkl', 'rb') as f:\n",
    "        label_encoders = pickle.load(f)\n",
    "\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    categorical_columns = ['Gender', 'Country', 'self_employed', 'family_history',\n",
    "                           'work_interfere', 'no_employees', 'remote_work', 'tech_company',\n",
    "                           'benefits', 'care_options', 'wellness_program', 'seek_help',\n",
    "                           'anonymity', 'leave', 'mental_health_consequence',\n",
    "                           'phys_health_consequence', 'coworkers', 'supervisor',\n",
    "                           'mental_health_interview', 'phys_health_interview',\n",
    "                           'mental_vs_physical', 'obs_consequence']\n",
    "\n",
    "    for column in categorical_columns:\n",
    "        known_categories = label_encoders[column].classes_\n",
    "        input_df[column] = input_df[column].apply(lambda x: x if x in known_categories else known_categories[0])\n",
    "        input_df[column] = label_encoders[column].transform(input_df[column])\n",
    "\n",
    "    input_df['Age'] = scaler.transform(input_df[['Age']])\n",
    "    prediction = model.predict(input_df)\n",
    "    probability = model.predict_proba(input_df)\n",
    "    return {'prediction': prediction[0], 'probability': probability[0].max()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b7f3327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Prediction:\n",
      "Prediction: 1\n",
      "Probability: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    example_input = {\n",
    "        'Age': 30,\n",
    "        'Gender': 'Male',\n",
    "        'Country': 'United States',\n",
    "        'self_employed': 'No',\n",
    "        'family_history': 'Yes',\n",
    "        'work_interfere': 'Sometimes',\n",
    "        'no_employees': '26-100',\n",
    "        'remote_work': 'No',\n",
    "        'tech_company': 'Yes',\n",
    "        'benefits': 'Yes',\n",
    "        'care_options': 'Yes',\n",
    "        'wellness_program': 'Yes',\n",
    "        'seek_help': 'Yes',\n",
    "        'anonymity': 'Yes',\n",
    "        'leave': 'Somewhat easy',\n",
    "        'mental_health_consequence': 'No',\n",
    "        'phys_health_consequence': 'No',\n",
    "        'coworkers': 'Yes',\n",
    "        'supervisor': 'Yes',\n",
    "        'mental_health_interview': 'No',\n",
    "        'phys_health_interview': 'No',\n",
    "        'mental_vs_physical': 'Yes',\n",
    "        'obs_consequence': 'No'\n",
    "    }\n",
    "\n",
    "    result = predict_mental_health(example_input)\n",
    "    print(\"\\nExample Prediction:\")\n",
    "    print(f\"Prediction: {result['prediction']}\")\n",
    "    print(f\"Probability: {result['probability']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
